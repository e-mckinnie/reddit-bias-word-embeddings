{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "\n",
    "Takes raw data in csvs.\n",
    "Filters and creates datasets for specific time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "from gensim.models import Phrases\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "import re\n",
    "from nltk.stem.util import suffix_replace\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def preprocess(filename=None, start_date=None, end_date=None):\n",
    "    # get data from csv\n",
    "    df = pd.read_csv(filename, index_col=\"id\", usecols=[\"id\", \"body\", \"author\", \"parent_id\", \"retrieved_on\", \"timestamp\"], parse_dates=['timestamp'])\n",
    "    \n",
    "    # filter by date\n",
    "    if start_date:\n",
    "        df = df[df.timestamp >= start_date]\n",
    "    if end_date:\n",
    "        df = df[df.timestamp < end_date]\n",
    "\n",
    "    # remove rows where comment was deleted\n",
    "    df = df.drop(df[df.body == \"[deleted]\"].index)\n",
    "    df = df.drop(df[df.body == \"[removed]\"].index)\n",
    "\n",
    "    # remove links, convert to lowercase, remove html special characters, tokenize, and remove short/long tokens\n",
    "    def pre_preprocessing(sentence):\n",
    "        spl = sentence.split()\n",
    "        for i, word in enumerate(spl):\n",
    "            parsed_url = urlparse(word)\n",
    "            if parsed_url.scheme and parsed_url.netloc:\n",
    "                spl[i] = \"removed_url\"\n",
    "        sentence = ' '.join(spl)\n",
    "        sentence = sentence.replace(\"&amp;\", \"and\")\n",
    "        sentence = sentence.replace(\"&gt;\", \"\")\n",
    "        # men and man, female and females, incel and incels, marginalized and marginalised, libfem and libfems\n",
    "        return simple_preprocess(sentence)\n",
    "    simple_preprocessed = df['body'].astype(str).apply(pre_preprocessing)\n",
    "\n",
    "    # function to lemmatize each token, based on its part of speech\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    def lemmatize_token(t: str, pos:str):\n",
    "        morphy_tag = {'NN':wn.NOUN, 'JJ':wn.ADJ,\n",
    "                  'VB':wn.VERB, 'RB':wn.ADV}\n",
    "        try:\n",
    "            pos = morphy_tag[pos[:2]]\n",
    "        except:\n",
    "            pos = wn.NOUN\n",
    "        lemma = lemmatizer.lemmatize(t, pos)\n",
    "        return lemma\n",
    "    \n",
    "    # task specific post-preprocessing\n",
    "    def post_preprocessing(t):\n",
    "        if t == \"men\":\n",
    "            t = suffix_replace(t, \"en\", \"an\")\n",
    "        elif t in [\"incels\", \"libfems\", \"females\"]:\n",
    "            t = suffix_replace(t, \"s\", \"\")\n",
    "        elif t in [\"marginalised\"]:\n",
    "            t = suffix_replace(t, \"ised\", \"ized\")\n",
    "        return t\n",
    "    \n",
    "    # tokenize comments, preserving common bigram phrases\n",
    "    # identify common bigram phrases\n",
    "    phrases = Phrases(simple_preprocessed, scoring=\"npmi\", threshold=0.7)\n",
    "    def preproccess_sentence(preprocessed_sentence: str) -> List[str]:\n",
    "        # combine tokens that make up a phrase and drop associated score\n",
    "        simple_tokens = [t[0] for t in phrases.analyze_sentence(preprocessed_sentence)]\n",
    "        # lemmatize tokens\n",
    "        tokens_and_pos = pos_tag(simple_tokens)\n",
    "        tokens = [lemmatize_token(t, pos) for t, pos in tokens_and_pos]\n",
    "        tokens = [post_preprocessing(t) for t in tokens]\n",
    "        return tokens\n",
    "    \n",
    "    # create body_clean column: a preprocessed version of body\n",
    "    df['body_clean'] = simple_preprocessed.apply(preproccess_sentence)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"data/raw/\"\n",
    "datasets = {\n",
    "    \"incels\": \n",
    "        {\n",
    "            \"filename\": prefix + \"Incels_comments.csv\",\n",
    "            \"start_date\": \"2015-11-07\"\n",
    "        },\n",
    "    \"braincels\": \n",
    "        {\n",
    "            \"filename\": prefix + \"Braincels_comments.csv\",\n",
    "            \"start_date\": \"2017-09-30\"\n",
    "        },\n",
    "    \"trufemcels\": \n",
    "        {\n",
    "            \"filename\": prefix + \"Trufemcels_comments.csv\",\n",
    "            \"start_date\": \"2019-01-30\"\n",
    "        },\n",
    "    \"mensrights\": \n",
    "        {\n",
    "            \"filename\": prefix + \"MensRights_comments.csv\",\n",
    "            \"start_date\": \"2021-01-01\"\n",
    "        },\n",
    "    \"theredpill\": \n",
    "        {\n",
    "            \"filename\": prefix + \"TheRedPill_comments.csv\",\n",
    "            \"start_date\": \"2021-01-01\"\n",
    "        },\n",
    "    \"feminism_full\": \n",
    "        {\n",
    "            \"filename\": prefix + \"Feminism_comments.csv\", \n",
    "            \"start_date\": \"2015-11-07\"\n",
    "        },\n",
    "    \"fourthwavewomen\": \n",
    "        {\n",
    "            \"filename\": prefix + \"fourthwavewomen_comments.csv\",\n",
    "            \"start_date\": \"2021-01-01\"\n",
    "        },\n",
    "    \"women\": \n",
    "        {\n",
    "            \"filename\": prefix + \"women_comments.csv\",\n",
    "            \"start_date\": \"2021-01-01\"\n",
    "        },\n",
    "    \"pinkpillfeminism\": \n",
    "        {\n",
    "            \"filename\": prefix + \"PinkpillFeminism_comments.csv\",\n",
    "            \"start_date\": \"2021-01-01\"\n",
    "        },\n",
    "    \"feminisms\": \n",
    "        {\n",
    "            \"filename\": prefix + \"feminisms_comments.csv\",\n",
    "            \"start_date\": \"2021-01-01\"\n",
    "        },\n",
    "    \"blackladies\": \n",
    "        {\n",
    "            \"filename\": prefix + \"blackladies_comments.csv\",\n",
    "            \"start_date\": \"2021-01-01\"\n",
    "        },\n",
    "    \"feminismuncensored\": \n",
    "        {\n",
    "            \"filename\": prefix + \"FeminismUncensored_comments.csv\",\n",
    "            \"start_date\": \"2021-01-01\"\n",
    "        },\n",
    "    \"fireyfemmes\": \n",
    "        {\n",
    "            \"filename\": prefix + \"FIREyFemmes_comments.csv\",\n",
    "            \"start_date\": \"2021-01-01\"\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bs/dn5ftycx50sgjnrrwnpdllth0000gn/T/ipykernel_27208/372815649.py:14: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=\"id\", usecols=[\"id\", \"body\", \"author\", \"parent_id\", \"retrieved_on\", \"timestamp\"], parse_dates=['timestamp'])\n",
      "/var/folders/bs/dn5ftycx50sgjnrrwnpdllth0000gn/T/ipykernel_27208/372815649.py:14: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=\"id\", usecols=[\"id\", \"body\", \"author\", \"parent_id\", \"retrieved_on\", \"timestamp\"], parse_dates=['timestamp'])\n",
      "/var/folders/bs/dn5ftycx50sgjnrrwnpdllth0000gn/T/ipykernel_27208/372815649.py:14: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=\"id\", usecols=[\"id\", \"body\", \"author\", \"parent_id\", \"retrieved_on\", \"timestamp\"], parse_dates=['timestamp'])\n",
      "/var/folders/bs/dn5ftycx50sgjnrrwnpdllth0000gn/T/ipykernel_27208/372815649.py:14: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=\"id\", usecols=[\"id\", \"body\", \"author\", \"parent_id\", \"retrieved_on\", \"timestamp\"], parse_dates=['timestamp'])\n",
      "/var/folders/bs/dn5ftycx50sgjnrrwnpdllth0000gn/T/ipykernel_27208/372815649.py:14: DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(filename, index_col=\"id\", usecols=[\"id\", \"body\", \"author\", \"parent_id\", \"retrieved_on\", \"timestamp\"], parse_dates=['timestamp'])\n"
     ]
    }
   ],
   "source": [
    "for subreddit in datasets:\n",
    "    try:\n",
    "        df = preprocess(**datasets[subreddit])\n",
    "        df.to_pickle(\"data/clean/\"+subreddit+\".pkl\")\n",
    "    except:\n",
    "        print(\"FAILED: \" + subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break feminism into time periods\n",
    "feminism_full = pd.read_pickle(\"data/clean/feminism_full.pkl\")\n",
    "feminism_chunks = []\n",
    "for i in range(2015, 2023, 2):\n",
    "    feminism_chunk = feminism_full[(feminism_full.timestamp >= str(i)+\"-01-01\") & (feminism_full.timestamp < str(i+2)+\"-01-01\")]\n",
    "    feminism_chunk.to_pickle(\"data/clean/feminism_\"+str(i)+\"_\"+str(i+2)+\".pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine incels into one df\n",
    "incel_subreddits = [\"incels\", \"braincels\", \"trufemcels\", \"mensrights\"] # add the redpill\n",
    "incel_dfs = [pd.read_pickle(\"data/clean/\"+subreddit+\".pkl\") for subreddit in incel_subreddits]\n",
    "full_df = pd.concat(incel_dfs)\n",
    "full_df.to_pickle(\"data/clean/incels_full.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "d38cpyp                        [reply, to, you, on, trucels]\n",
      "d38dsz9    [seduction, be, disastrous, for, woman, since,...\n",
      "d38e0dh    [thank, you, it, hearten, to, see, more, and, ...\n",
      "d3ej70j    [you, describe, yourself, a, non, chad, would,...\n",
      "d3ek59w    [rate, my, attractiveness, maybe, out, of, my,...\n",
      "Name: body_clean, dtype: object\n",
      "id\n",
      "doo7s2k    [why, do, not, have, fifty, subscriber, alread...\n",
      "doo85t6    [here, some, previous, essay, story, and, poet...\n",
      "dopbxoz                     [subscribe, do, get, an, upvote]\n",
      "dopbyxv    [hate, psychology, it, brainwash, gimmick, to,...\n",
      "dopcfvs    [damn, literally, study, cognitive, behavioral...\n",
      "Name: body_clean, dtype: object\n",
      "id\n",
      "efb6vdz    [isn, the, girl, from, vampire, diary, bulgari...\n",
      "efb6zku    [even, for, satire, eww, blehh, doesn, the, av...\n",
      "efb72bt    [eh, wouldn, say, beautiful, woman, feel, unco...\n",
      "efb7b2g    [yeah, not, say, she, doesn, face, her, own, i...\n",
      "efb7c7o                                  [all, the, fresher]\n",
      "Name: body_clean, dtype: object\n",
      "id\n",
      "ghnn77t    [glad, to, see, some, country, be, reform, it,...\n",
      "ghnn8n6    [not, sure, this, woman, be, the, best, spokes...\n",
      "ghnn9jp    [it, common, for, woman, to, rely, upon, plaus...\n",
      "ghnnldv    [you, haven, see, any, of, her, video, other, ...\n",
      "ghno0jg                                               [good]\n",
      "Name: body_clean, dtype: object\n",
      "id\n",
      "d38cpyp                        [reply, to, you, on, trucels]\n",
      "d38dsz9    [seduction, be, disastrous, for, woman, since,...\n",
      "d38e0dh    [thank, you, it, hearten, to, see, more, and, ...\n",
      "d3ej70j    [you, describe, yourself, a, non, chad, would,...\n",
      "d3ek59w    [rate, my, attractiveness, maybe, out, of, my,...\n",
      "Name: body_clean, dtype: object\n",
      "id\n",
      "cwrahh1    [there, an, article, by, wendy, faulkner, http...\n",
      "cwralnk    [lot, of, people, might, think, it, graphic, t...\n",
      "cwraz6x    [people, often, hate, on, feminist, for, take,...\n",
      "cwrb08a    [ve, read, before, that, these, farm, be, also...\n",
      "cwrb4vq    [this, one, http_www, nrc, usda, gov, internet...\n",
      "Name: body_clean, dtype: object\n",
      "id\n",
      "cwrahh1    [there, an, article, by, wendy, faulkner, http...\n",
      "cwralnk    [lot, of, people, might, think, it, graphic, t...\n",
      "cwraz6x    [people, often, hate, on, feminist, for, take,...\n",
      "cwrb08a    [ve, read, before, that, these, farm, be, also...\n",
      "cwrb4vq    [this, one, http_www, nrc, usda, gov, internet...\n",
      "Name: body_clean, dtype: object\n",
      "id\n",
      "dbunawq    [ok, go, to, base, my, understanding, of, thes...\n",
      "dbuniis    [both, woman, and, man, have, pubic, hair, so,...\n",
      "dbuo7i4    [write, by, someone, who, doesn, know, what, t...\n",
      "dbuo87u    [really, wish, more, people, would, understand...\n",
      "dbuo883    [it, because, society, have, say, so, for, ver...\n",
      "Name: body_clean, dtype: object\n",
      "id\n",
      "eczc7y0    [whoa_whoa, whoa_whoa, hold, up, woman, like, ...\n",
      "eczdlrt    [that, be, exactly, how, feel, don, need, to, ...\n",
      "eczduf6                                   [happy, new, year]\n",
      "eczfaxq    [my, family, recently, move, to, location, clo...\n",
      "eczg6e0    [it, ironic, because, back, then, prostitution...\n",
      "Name: body_clean, dtype: object\n",
      "id\n",
      "ghnopkr                                     [pretty, common]\n",
      "ghnpmud    [how, do, that, work, why, don, they, worry, a...\n",
      "ghnqq1x    [im, not, sure, but, she, definitely, cod, whi...\n",
      "ghnqtml    [mras, abuse, their, own, advocacy, to, try, a...\n",
      "ghnqwsp    [if, you, ask, me, yes, but, it, not, present,...\n",
      "Name: body_clean, dtype: object\n",
      "id\n",
      "h5freak    [would, love, to, add, third, point, and, that...\n",
      "h5frqmg             [great, we, will, add, flair, for, that]\n",
      "h5ftcsx    [have, just, try, to, do, test, but, cannot, y...\n",
      "h5fuxxe    [we, be, in, the, process, of, add, the, flair...\n",
      "h5fwhdm    [be, young, woman, who, be, bear, into, the, t...\n",
      "Name: body_clean, dtype: object\n",
      "id\n",
      "ghnoz16    [thankful, for, the, post, be, well, and, cong...\n",
      "ghnq5yx    [thankful, for, you, for, be, here, lt, always...\n",
      "ghnw596    [love, black, woman, but, sometimes, those, ba...\n",
      "ghnx39k    [thank, you, for, this, well, need, post, and,...\n",
      "ghny1eu    [hi, white, but, most, of, my, co_workers, be,...\n",
      "Name: body_clean, dtype: object\n",
      "Series([], Name: body_clean, dtype: object)\n",
      "id\n",
      "ghnwq78    [there, be, good, chance, that, this, wasn, se...\n",
      "ghnx1e3    [sometimes, the, marshmallow, must, go, to, du...\n",
      "ghooaxk    [dang, paywall, the, subtitle, be, pretty, inf...\n",
      "ghpe4hg             [that, how, feminist, make, some, noise]\n",
      "ghshxcc    [find, this, removed_url, look, like, multiple...\n",
      "Name: body_clean, dtype: object\n",
      "id\n",
      "ghnmzjf    [my, mom, pick, up, the, ingredient, today, we...\n",
      "ghnn75u                           [happy, independence, day]\n",
      "ghnnckr    [same, some, think, saditty, or, that, try, to...\n",
      "ghnon6v    [think, it, actually, the, opposite, imo, grow...\n",
      "ghnpdi2    [wow, so, much, be, the, same, have, bw, manag...\n",
      "Name: body_clean, dtype: object\n",
      "id\n",
      "gihe7k1    [welcome, to, feminism, we, welcome, all, peop...\n",
      "gmpw3ok               [you, can, it, be, just, prefer, here]\n",
      "grzqlba    [you, ve, already, hear, my, side, of, the, st...\n",
      "grzqwfz    [happy, to, see, that, this, sub, exist, thank...\n",
      "gs1lbs4    [don, think, infinitysky, put, any, filter, up...\n",
      "Name: body_clean, dtype: object\n",
      "id\n",
      "ghnp6g3    [grateful, that, all, my, friend, and, family,...\n",
      "ghnpgsa    [super, thankful, for, the, good, thing, that,...\n",
      "ghnrxoc    [if, you, have, target, redcard, you, can, get...\n",
      "ghnsu1t    [thankful, that, survive, chemotherapy, be, di...\n",
      "gho3gom    [thankful, for, my, friend, and, family, who, ...\n",
      "Name: body_clean, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# manually inspect results\n",
    "def load_df(subreddit, prefix=\"data/clean/\"):\n",
    "    df = pd.read_pickle(prefix+subreddit+\".pkl\")\n",
    "    return df\n",
    "subreddits = [\"incels\", \"braincels\", \"trufemcels\", \"mensrights\", \"incels_full\",\"feminism_full\", \"feminism_2015_2017\", \"feminism_2017_2019\", \"feminism_2019_2021\", \"feminism_2021_2023\", \"fourthwavewomen\", \"women\", \"feminisms\", \"blackladies\", \"feminismuncensored\", \"fireyfemmes\", \"pinkpillfeminism\"]\n",
    "for subreddit in subreddits:\n",
    "    print(load_df(subreddit)[\"body_clean\"].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
