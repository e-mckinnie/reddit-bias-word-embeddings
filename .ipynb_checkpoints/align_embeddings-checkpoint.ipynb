{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ed2eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, callbacks\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08366a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_incels = Word2Vec.load('../data/embeddings/embeddings/incels_full.bin')\n",
    "embed_feminism = Word2Vec.load('../data/embeddings/embeddings/feminism_full.bin')\n",
    "embed_braincels = Word2Vec.load('../data/embeddings/embeddings/braincels.bin')\n",
    "embed_fourthwavewomen = Word2Vec.load('../data/embeddings/embeddings/fourthwavewomen.bin')\n",
    "embed_mensrights = Word2Vec.load('../data/embeddings/embeddings/mensrights.bin')\n",
    "embed_trufemcels = Word2Vec.load('../data/embeddings/embeddings/trufemcels.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd6b401d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('people', 0.37149709463119507),\n",
       " ('femcels', 0.3666529357433319),\n",
       " ('themselves', 0.3534865975379944),\n",
       " ('normies', 0.3458905518054962),\n",
       " ('girl', 0.33657538890838623)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_trufemcels.wv.most_similar(\"woman\", negative=\"man\", topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8ba8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_procrustes_align_gensim(base_embed, other_embed, words=None):\n",
    "    \"\"\"\n",
    "    Original script: https://gist.github.com/quadrismegistus/09a93e219a6ffc4f216fb85235535faf\n",
    "    Procrustes align two gensim word2vec models (to allow for comparison between same word across models).\n",
    "    Code ported from HistWords <https://github.com/williamleif/histwords> by William Hamilton <wleif@stanford.edu>.\n",
    "        \n",
    "    First, intersect the vocabularies (see `intersection_align_gensim` documentation).\n",
    "    Then do the alignment on the other_embed model.\n",
    "    Replace the other_embed model's syn0 and syn0norm numpy matrices with the aligned version.\n",
    "    Return other_embed.\n",
    "    If `words` is set, intersect the two models' vocabulary with the vocabulary in words (see `intersection_align_gensim` documentation).\n",
    "    \"\"\"\n",
    "\n",
    "    # patch by Richard So [https://twitter.com/richardjeanso) (thanks!) to update this code for new version of gensim\n",
    "    # base_embed.init_sims(replace=True)\n",
    "    # other_embed.init_sims(replace=True)\n",
    "\n",
    "    # make sure vocabulary and indices are aligned\n",
    "    in_base_embed, in_other_embed = intersection_align_gensim(base_embed, other_embed, words=words)\n",
    "\n",
    "    # get the (normalized) embedding matrices\n",
    "    base_vecs = in_base_embed.wv.get_normed_vectors()\n",
    "    other_vecs = in_other_embed.wv.get_normed_vectors()\n",
    "\n",
    "    # just a matrix dot product with numpy\n",
    "    m = other_vecs.T.dot(base_vecs) \n",
    "    # SVD method from numpy\n",
    "    u, _, v = np.linalg.svd(m)\n",
    "    # another matrix operation\n",
    "    ortho = u.dot(v) \n",
    "    # Replace original array with modified one, i.e. multiplying the embedding matrix by \"ortho\"\n",
    "    other_embed.wv.vectors = (other_embed.wv.vectors).dot(ortho)    \n",
    "    \n",
    "    return other_embed\n",
    "\n",
    "def intersection_align_gensim(m1, m2, words=None):\n",
    "    \"\"\"\n",
    "    Intersect two gensim word2vec models, m1 and m2.\n",
    "    Only the shared vocabulary between them is kept.\n",
    "    If 'words' is set (as list or set), then the vocabulary is intersected with this list as well.\n",
    "    Indices are re-organized from 0..N in order of descending frequency (=sum of counts from both m1 and m2).\n",
    "    These indices correspond to the new syn0 and syn0norm objects in both gensim models:\n",
    "        -- so that Row 0 of m1.syn0 will be for the same word as Row 0 of m2.syn0\n",
    "        -- you can find the index of any word on the .index2word list: model.index2word.index(word) => 2\n",
    "    The .vocab dictionary is also updated for each model, preserving the count but updating the index.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the vocab for each model\n",
    "    vocab_m1 = set(m1.wv.index_to_key)\n",
    "    vocab_m2 = set(m2.wv.index_to_key)\n",
    "\n",
    "    # Find the common vocabulary\n",
    "    common_vocab = vocab_m1 & vocab_m2\n",
    "    if words: common_vocab &= set(words)\n",
    "\n",
    "    # If no alignment necessary because vocab is identical...\n",
    "    if not vocab_m1 - common_vocab and not vocab_m2 - common_vocab:\n",
    "        return (m1,m2)\n",
    "\n",
    "    # Otherwise sort by frequency (summed for both)\n",
    "    common_vocab = list(common_vocab)\n",
    "    common_vocab.sort(key=lambda w: m1.wv.get_vecattr(w, \"count\") + m2.wv.get_vecattr(w, \"count\"), reverse=True)\n",
    "    # print(len(common_vocab))\n",
    "\n",
    "    # Then for each model...\n",
    "    for m in [m1, m2]:\n",
    "        # Replace old syn0norm array with new one (with common vocab)\n",
    "        indices = [m.wv.key_to_index[w] for w in common_vocab]\n",
    "        old_arr = m.wv.vectors\n",
    "        new_arr = np.array([old_arr[index] for index in indices])\n",
    "        m.wv.vectors = new_arr\n",
    "\n",
    "        # Replace old vocab dictionary with new one (with common vocab)\n",
    "        # and old index2word with new one\n",
    "        new_key_to_index = {}\n",
    "        new_index_to_key = []\n",
    "        for new_index, key in enumerate(common_vocab):\n",
    "            new_key_to_index[key] = new_index\n",
    "            new_index_to_key.append(key)\n",
    "        m.wv.key_to_index = new_key_to_index\n",
    "        m.wv.index_to_key = new_index_to_key\n",
    "        \n",
    "        print(len(m.wv.key_to_index), len(m.wv.vectors))\n",
    "        \n",
    "    return (m1,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fa412f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12672 12672\n",
      "12672 12672\n"
     ]
    }
   ],
   "source": [
    "# embed_incels_aligned = smart_procrustes_align_gensim(embed_feminism, embed_incels, words=None)\n",
    "# embed_braincels_aligned = smart_procrustes_align_gensim(embed_feminism, embed_braincels, words=None)\n",
    "embed_fourthwavewomen_aligned = smart_procrustes_align_gensim(embed_feminism, embed_fourthwavewomen, words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bad44af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12017 12017\n",
      "12017 12017\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (12017,300) (12672,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embed_incels_aligned \u001b[38;5;241m=\u001b[39m smart_procrustes_align_gensim(embed_feminism, embed_incels, words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m, in \u001b[0;36msmart_procrustes_align_gensim\u001b[0;34m(base_embed, other_embed, words)\u001b[0m\n\u001b[1;32m     19\u001b[0m in_base_embed, in_other_embed \u001b[38;5;241m=\u001b[39m intersection_align_gensim(base_embed, other_embed, words\u001b[38;5;241m=\u001b[39mwords)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# get the (normalized) embedding matrices\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m base_vecs \u001b[38;5;241m=\u001b[39m in_base_embed\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mget_normed_vectors()\n\u001b[1;32m     23\u001b[0m other_vecs \u001b[38;5;241m=\u001b[39m in_other_embed\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mget_normed_vectors()\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# just a matrix dot product with numpy\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/gensim/models/keyedvectors.py:697\u001b[0m, in \u001b[0;36mKeyedVectors.get_normed_vectors\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get all embedding vectors normalized to unit L2 length (euclidean), as a 2D numpy array.\u001b[39;00m\n\u001b[1;32m    685\u001b[0m \n\u001b[1;32m    686\u001b[0m \u001b[38;5;124;03mTo see which key corresponds to which vector = which array row, refer\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    694\u001b[0m \n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_norms()\n\u001b[0;32m--> 697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectors \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorms[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (12017,300) (12672,1) "
     ]
    }
   ],
   "source": [
    "embed_incels_aligned = smart_procrustes_align_gensim(embed_feminism, embed_incels, words=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06767f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
